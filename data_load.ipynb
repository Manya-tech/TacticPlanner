{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b4bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel\n",
    "df = pd.read_excel(\"department_marketing_mix_data.xlsx\")\n",
    "\n",
    "# Combine relevant text fields (e.g., Channel + Department + Year) into a single string\n",
    "df[\"text\"] = df.apply(lambda row: f\"{row['Department']} department ran {row['Channel']} campaign in {row['Year']}. Spend: {row['Spend']}, ROI: {row['ROI']}, Incremental ROI: {row['Incremental ROI']}\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cbc228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(df[\"text\"].tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb07ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy float32\n",
    "embedding_matrix = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(embedding_matrix.shape[1])  # L2 = Euclidean distance\n",
    "index.add(embedding_matrix)\n",
    "\n",
    "# Optional: Save the index\n",
    "faiss.write_index(index, \"faiss_mmm_index.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0772b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital department ran Social Media campaign in 2022. Spend: 42705.7, ROI: 1.93, Incremental ROI: 1.68\n",
      "Digital department ran Content Marketing campaign in 2023. Spend: 44610.26, ROI: 2.02, Incremental ROI: 1.58\n",
      "Digital department ran Social Media campaign in 2023. Spend: 41307.43, ROI: 2.12, Incremental ROI: 1.91\n",
      "Digital department ran Social Media campaign in 2024. Spend: 29335.73, ROI: 0.66, Incremental ROI: 0.14\n",
      "Digital department ran Content Marketing campaign in 2022. Spend: 39964.12, ROI: 1.72, Incremental ROI: 1.22\n"
     ]
    }
   ],
   "source": [
    "query = \"Digital campaigns in 2023 with high ROI\"\n",
    "query_embedding = model.encode([query]).astype(\"float32\")\n",
    "\n",
    "# Search top 5 similar entries\n",
    "distances, indices = index.search(query_embedding, k=5)\n",
    "\n",
    "# Print results\n",
    "for i in indices[0]:\n",
    "    print(df.iloc[i][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a92eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed1a1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc6a69e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"deepseek-r1:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c04eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index\n",
    "index = faiss.read_index(\"faiss_mmm_index.index\")\n",
    "\n",
    "# Load metadata (your Excel)\n",
    "df = pd.read_excel(\"department_marketing_mix_data.xlsx\")\n",
    "\n",
    "# Load sentence embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb84da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.apply(lambda row: f\"In {row['Year']}, the ROI for {row['Channel']} in {row['Department']} was {row['ROI']}.\", axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc5f06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d589df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "with open(\"metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be92d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e999d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get top-k documents\n",
    "def retrieve_context(query, k=3):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    D, I = index.search(query_embedding, k)\n",
    "    return [metadata[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8351bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_deepseek(prompt, max_tokens=300):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=max_tokens)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def agentic_rag_chat():\n",
    "    chat_history = \"\"\n",
    "    while True:\n",
    "        user_query = input(\"User: \")\n",
    "\n",
    "        context = retrieve_context(user_query)\n",
    "        if not any(context):\n",
    "            follow_up = \"I couldn't find enough information. Can you tell me more? For example, which department or year?\"\n",
    "            print(f\"Agent: {follow_up}\")\n",
    "            clarification = input(\"User: \")\n",
    "            context = retrieve_context(clarification + \" \" + user_query)\n",
    "\n",
    "        context_str = \"\\n\".join(context)\n",
    "        prompt = f\"Context:\\n{context_str}\\n\\nQuestion: {user_query}\\nAnswer:\"\n",
    "        response = ask_deepseek(prompt)\n",
    "        print(f\"Agent: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137af26",
   "metadata": {},
   "source": [
    "####generate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1167c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Data and FAISS Index\n",
    "df = pd.read_excel(\"department_marketing_mix_data.xlsx\")\n",
    "df[\"text\"] = df.apply(lambda row: f\"{row['Department']} department ran {row['Channel']} campaign in {row['Year']}. Spend: {row['Spend']}, ROI: {row['ROI']}, Incremental ROI: {row['Incremental ROI']}\", axis=1)\n",
    "\n",
    "# Load embedding model\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"faiss_mmm_index.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_documents(query, top_k=5):\n",
    "    query_embedding = embed_model.encode([query]).astype(\"float32\")\n",
    "    distances, indices = index.search(query_embedding, k=top_k)\n",
    "    \n",
    "    docs = []\n",
    "    for idx in indices[0]:\n",
    "        text = df.iloc[idx][\"text\"]\n",
    "        docs.append(Document(page_content=text))\n",
    "    return docs\n",
    "\n",
    "# Step 4: Define DeepSeek Model + Prompt Template\n",
    "LANGUAGE_MODEL = OllamaLLM(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a strategic pharma marketing assistant. Use the provided context to help with marketing tactic planning.\n",
    "If the context is insufficient to answer the query confidently, say so and ask the user a clarification question.\n",
    "Limit your response to 3 sentences max. Be concise and data-driven.\n",
    "\n",
    "Query: {user_query} \n",
    "Context: {document_context} \n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cf85902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Main Chat Loop (Agentic Behavior)\n",
    "def start_agentic_chat():\n",
    "    print(\"ðŸ“Š Pharma Tactic Planner - Agentic RAG Chatbot (DeepSeek R1)\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    chat_history = []\n",
    "    while True:\n",
    "        user_query = input(\"ðŸ§  You: \")\n",
    "        if user_query.lower() == \"exit\":\n",
    "            print(\"ðŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "\n",
    "        docs = retrieve_similar_documents(user_query, top_k=5)\n",
    "\n",
    "        if not docs or len(docs) < 2:\n",
    "            print(\"ðŸ¤” Not enough relevant data found. Can you provide more context or rephrase your question?\")\n",
    "            continue\n",
    "\n",
    "        answer = generate_answer(user_query, docs)\n",
    "        print(f\"ðŸ¤– DeepSeek: {answer}\")\n",
    "\n",
    "        # Store in history for potential use later\n",
    "        chat_history.append({\"user\": user_query, \"bot\": answer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a4f284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Pharma Tactic Planner - Agentic RAG Chatbot (DeepSeek R1)\n",
      "Type 'exit' to end the conversation.\n",
      "\n",
      "ðŸ¤– DeepSeek: <think>\n",
      "Okay, let me try to figure this out. The user provided some data from an HR department's recruitment portals campaign across several years and their associated costs and ROI. They want a marketing tactic plan based on this context. \n",
      "\n",
      "First, I notice the data spans from 2021 to 2024, with spending increasing each year but ROI also fluctuating. The incremental ROI shows how much value the new campaigns added compared to previous ones. So, the company's campaigns seem profitable when viewed in isolation and had varying returns when compared over time.\n",
      "\n",
      "The user might be looking for a strategy to enhance future campaigns or compare past efforts. They likely want actionable steps based on this data. I should break down each year's performance and see where the company can leverage these findings.\n",
      "\n",
      "They could benefit from expanding the campaign, adjusting strategies based on incremental ROI trends, maybe offering new opportunities in areas with higher spending but lower costs. Also, comparing against the previous campaigns' ROI changes might help them adjust their future plans accordingly.\n",
      "</think>\n",
      "\n",
      "HR department campaigns have shown increasing profitability over time, with incremental ROI indicating that newer efforts were more effective than older ones (e.g., 3.47 for 2024 compared to 0.06 for 2023). This data suggests that the company can focus on optimizing future campaigns or adjust strategies based on performance trends.\n",
      "ðŸ‘‹ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Start the RAG Chat\n",
    "start_agentic_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8a90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
