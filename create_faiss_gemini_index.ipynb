{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93025ff1",
   "metadata": {},
   "source": [
    "# Create FAISS Index with Gemini Embeddings\n",
    "This notebook demonstrates how to generate document embeddings using the Google Gemini model and build a FAISS index for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6588efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0ea544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_mistralai import MistralAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03391e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables and API Keys\n",
    "load_dotenv()\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"MISTRAL_API_KEY not found in environment. Please set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4824d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess Data\n",
    "df = pd.read_excel(\"data/Sample data.xlsx\")\n",
    "df[\"text\"] = df.apply(lambda row: f\"{row['Brand']} brand ran {row['Category']} campaign using {row['Tactic']} in {row['Timeperiod']}. Spend: {row['$ Spend (MM)']}, Contribution: {row['$ Contribution']}, ROI: {row['ROI']}, Incremental ROI: {row['iROI']}\", axis=1)\n",
    "\n",
    "# Validate data preprocessing\n",
    "if df.empty:\n",
    "    raise ValueError(\"Data source is empty or invalid. Please check the file.\")\n",
    "\n",
    "document_texts = list(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae12259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MANYA\\OneDrive\\Desktop\\TacticPlanner\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\MANYA\\OneDrive\\Desktop\\TacticPlanner\\.conda\\Lib\\site-packages\\langchain_mistralai\\embeddings.py:186: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MANYA\\OneDrive\\Desktop\\TacticPlanner\\.conda\\Lib\\site-packages\\langchain_mistralai\\embeddings.py:186: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\"\n",
    ")\n",
    "try:\n",
    "    raw_doc_embeddings = embed_model.embed_documents(document_texts)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error generating embeddings: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4547eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Embeddings\n",
    "from numpy.linalg import norm\n",
    "try:\n",
    "    doc_embeddings = [np.array(e) / norm(e) for e in raw_doc_embeddings]\n",
    "    doc_embeddings_np = np.stack(doc_embeddings)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error normalizing embeddings: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f7414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_embeddings_np shape: (124, 1024), embedding dimension: 1024\n",
      "FAISS index created with 124 vectors of dimension 1024.\n"
     ]
    }
   ],
   "source": [
    "# Create and Populate FAISS Index\n",
    "actual_dim = doc_embeddings_np.shape[1]\n",
    "print(f\"doc_embeddings_np shape: {doc_embeddings_np.shape}, embedding dimension: {actual_dim}\")\n",
    "if doc_embeddings_np.dtype != np.float32:\n",
    "    doc_embeddings_np = doc_embeddings_np.astype(np.float32)\n",
    "try:\n",
    "    index = faiss.IndexFlatL2(actual_dim)\n",
    "    index.add(doc_embeddings_np)\n",
    "    print(f\"FAISS index created with {index.ntotal} vectors of dimension {actual_dim}.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error creating FAISS index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0379bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to faiss_mmm_index.index.\n",
      "Loaded FAISS index with 124 vectors.\n"
     ]
    }
   ],
   "source": [
    "# Save and Load FAISS Index\n",
    "try:\n",
    "    faiss.write_index(index, \"faiss_mmm_index.index\")\n",
    "    print(\"FAISS index saved to faiss_mmm_index.index.\")\n",
    "\n",
    "    # To load the index later:\n",
    "    loaded_index = faiss.read_index(\"faiss_mmm_index.index\")\n",
    "    print(f\"Loaded FAISS index with {loaded_index.ntotal} vectors.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error saving or loading FAISS index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09379bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
